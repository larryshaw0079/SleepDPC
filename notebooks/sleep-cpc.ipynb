{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom collections import namedtuple\n\nfrom tqdm.notebook import tqdm\ntry:\n    from rich.progress import track\nexcept:\n    !pip install rich\n    from rich.progress import track","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input/sleepedf-lite-0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom torch.utils.data import Dataset, DataLoader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Config = namedtuple('Config', ['seq_len', 'input_channels', 'hidden_channels', 'stride', \n                               'batch_size', 'num_seq', 'pred_steps', 'feature_dim',\n                               'learning_rate', 'train_ratio', 'epochs', 'save_path',\n                               'num_classes', 'finetune_ratio', 'finetune_epochs'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"args = Config(\n    seq_len=20,\n    stride=1,\n    input_channels=2,\n    hidden_channels=16,\n    batch_size=16,\n    num_seq=20,\n    pred_steps=5,\n    feature_dim=128,\n    learning_rate=1e-3,\n    train_ratio=0.7,\n    epochs=10,\n    save_path='/kaggle/working/check_points/',\n    num_classes=5,\n    finetune_ratio=0.1,\n    finetune_epochs=10\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preparing"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SleepEDFDataset(Dataset):\n    def __init__(self, path, seq_len, stride=1, patients=2, return_label=False):\n        self.return_label = return_label\n        self.seq_len = seq_len\n        \n        assert os.path.exists(path)\n        file_names = os.listdir(path)\n        \n        candidate_data = []\n        candidate_target = []\n        \n        for filename in file_names[:patients]:\n            data = np.load(os.path.join(path, filename))\n            candidate_data.append(\n                np.concatenate(\n                    (data['eeg_fpz_cz'].reshape(-1, 1, data['eeg_fpz_cz'].shape[-1]), \n                     data['eeg_pz_oz'].reshape(-1, 1, data['eeg_pz_oz'].shape[-1])), \n                axis=1)\n            )\n            candidate_target.append(data['annotation'] - 1)\n        candidate_data = np.concatenate(candidate_data, axis=0)\n        candidate_target = np.concatenate(candidate_target, axis=0)\n        \n        self.data = []\n        self.targets = []\n        for i in tqdm(range(0, len(candidate_data), stride)):\n            if (i + seq_len > len(candidate_data)):\n                break\n            self.data.append(np.expand_dims(candidate_data[i: i + seq_len], axis=0))\n            self.targets.append(np.expand_dims(candidate_target[i: i + seq_len], axis=0))\n        self.data = np.concatenate(self.data, axis=0)\n        self.targets = np.concatenate(self.targets, axis=0)\n        \n    def __len__(self):\n        return len(self.data)\n        \n    def __getitem__(self, item):\n        if self.return_label:\n            return (\n                torch.from_numpy(self.data[item].astype(np.float32)), \n                torch.from_numpy(self.targets[item].astype(np.long))\n            )\n        else:\n            return torch.from_numpy(self.data[item].astype(np.float32))\n        \n    def __repr__(self):\n        return f\"\"\"\n               ****************************************\n               Model  : {self.__class__.__name__}\n               Length : {len(self)}\n               ****************************************\n                \"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Backbones"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, input_channels, output_channels, kernel_sizes=[7, 11, 7], stride=1, dropout=0.2):\n        super(ResidualBlock, self).__init__()\n        self.input_channels = input_channels\n        self.output_channels = output_channels\n        self.stride = stride\n        \n        assert len(kernel_sizes) == 3\n\n        self.conv1 = nn.Sequential(\n            nn.Conv1d(input_channels, output_channels, kernel_size=kernel_sizes[0], stride=1, \n                      padding=kernel_sizes[0]//2, bias=False),\n            nn.BatchNorm1d(output_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        # Only conv2 degrades the scale\n        self.conv2 = nn.Sequential(\n            nn.Conv1d(output_channels, output_channels, kernel_size=kernel_sizes[1], stride=stride, \n                      padding=kernel_sizes[1]//2, bias=False),\n            nn.BatchNorm1d(output_channels),\n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout)\n        )\n\n        self.conv3 = nn.Sequential(\n            nn.Conv1d(output_channels, output_channels, kernel_size=kernel_sizes[2], stride=1, \n                      padding=kernel_sizes[2]//2, bias=False),\n            nn.BatchNorm1d(output_channels),\n        )\n\n        self.relu = nn.ReLU(inplace=True)\n\n\n        # If stride == 1, the length of the time dimension will not be changed\n        # If input_channels == output_channels, the number of channels will not be changed\n        # If the channels are mismatch, the conv1d is used to upgrade the channel\n        # If the time dimensions are mismatch, the conv1d is used to downsample the scale\n        self.downsample = nn.Sequential()\n        if stride != 1 or input_channels != output_channels:\n            self.downsample = nn.Sequential(\n                nn.Conv1d(input_channels, output_channels, kernel_size=1, stride=stride, padding=0, bias=False),\n                nn.BatchNorm1d(output_channels)\n            )\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.conv2(out)\n        out = self.conv3(out)\n\n        # Downsampe is an empty list if the size of inputs and outputs are same\n        residual = self.downsample(x) \n        out += residual\n        out = self.relu(out)\n        \n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResNet(nn.Module):\n    def __init__(self, input_channels, hidden_channels, num_classes, kernel_sizes=[7, 11, 7]):\n        super(ResNet, self).__init__()\n\n        # The first convolution layer\n#         self.conv1 = nn.Sequential(\n#             nn.Conv1d(input_channels, hidden_channels, kernel_size=15, stride=2, padding=7, bias=False),\n#             nn.BatchNorm1d(hidden_channels),\n#             nn.ReLU(inplace=True),\n#             nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n#         )\n        self.conv1 = nn.Sequential(\n            nn.Conv1d(input_channels, hidden_channels, kernel_size=1, padding=0, bias=False),\n            nn.BatchNorm1d(hidden_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        # Residual layers\n        self.layer1 = self.__make_layer(ResidualBlock, hidden_channels, hidden_channels, 2, kernel_sizes, stride=1)\n        self.layer2 = self.__make_layer(ResidualBlock, hidden_channels, hidden_channels*2, 2, kernel_sizes, stride=2)\n        self.layer3 = self.__make_layer(ResidualBlock, hidden_channels*2, hidden_channels*4, 2, kernel_sizes, stride=2)\n        self.layer4 = self.__make_layer(ResidualBlock, hidden_channels*4, hidden_channels*8, 2, kernel_sizes, stride=2)\n\n        self.avg_pool = nn.AdaptiveAvgPool1d(1) # Pooling operation computes the average of the last dimension (time dimension)\n\n        # A dense layer for output\n        self.fc = nn.Linear(hidden_channels*8, num_classes)\n\n        # Initialize weights\n#         for m in self.modules():\n#             if isinstance(m, nn.Conv1d):\n#                 n = m.kernel_size[0] * m.kernel_size[0] * m.out_channels\n#                 m.weight.data.normal_(0, math.sqrt(2. / n))\n#             elif isinstance(m, nn.BatchNorm1d):\n#                 m.weight.data.fill_(1)\n#                 m.bias.data.zero_()\n\n    def __make_layer(self, block, input_channels, output_channels, num_blocks, kernel_sizes, stride):\n        layers = []\n        layers.append(block(input_channels, output_channels, kernel_sizes, stride=stride))\n        for i in range(1, num_blocks):\n            layers.append(block(output_channels, output_channels, stride=1))        \n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        \"\"\"\n        L_out = floor[(L_in + 2*padding - kernel) / stride + 1]\n        \"\"\"\n        out = self.conv1(x)          \n        out = self.layer1(out)     \n        out = self.layer2(out)  \n        out = self.layer3(out) \n        out = self.layer4(out)    \n\n        out = self.avg_pool(out)\n        out = out.view(x.size(0), -1)\n        out = self.fc(out)\n\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class GRU(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, dropout=0.3):\n        super(GRU, self).__init__()\n        \n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.dropout = dropout\n        \n        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, \n                          batch_first=True, dropout=dropout)\n        \n    def forward(self, x, h_0):\n        # x:   (batch, seq_len,    input_size)\n        # h_0: (num_layers, batch, hidden_size)\n        \n        out, h_n = self.gru(x, h_0)\n        \n        # out: (batch, seq_len, hidden_size)\n        # h_n: (num_layers, batch, hidden_size)\n        return out, h_n\n        \n    \n    def init_hidden(self, batch_size):\n        return torch.randn(self.num_layers, batch_size, self.hidden_size).cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class StatePredictor(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(StatePredictor, self).__init__()\n        \n        self.pred = nn.Sequential(\n            nn.Linear(input_dim, output_dim),\n            nn.ReLU(inplace=True),\n            nn.Linear(output_dim, output_dim)\n        )\n    \n    def forward(self, x):\n        return self.pred(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The Sleep Contrast Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SleepContrast(nn.Module):\n    def __init__(self, input_channels, hidden_channels, feature_dim, pred_steps, num_seq, batch_size, kernel_sizes):\n        super(SleepContrast, self).__init__()\n        \n        self.input_channels = input_channels\n        self.hidden_channels = hidden_channels\n        self.feature_dim = feature_dim\n        self.pred_steps = pred_steps\n        self.num_seq = num_seq\n        self.batch_size = batch_size\n        self.kernel_sizes = kernel_sizes\n        \n        self.targets = None\n        \n        # Local Encoder\n        self.encoder = ResNet(input_channels, hidden_channels, feature_dim, kernel_sizes=kernel_sizes)\n        \n        # Memory bank\n#         memory_bank = torch.randn(total_size, output_length) \n#         self.register_buffer('memory_bank', memory_bank)\n        \n        # Aggregator\n        self.gru = GRU(input_size=feature_dim, hidden_size=feature_dim, num_layers=2)\n        \n        # Predictor\n        self.predictor = StatePredictor(input_dim=feature_dim, output_dim=feature_dim)\n        \n#     def _initialize_weights(self, module):\n#         for name, param in module.named_parameters():\n#             if 'bias' in name:\n#                 nn.init.constant_(param, 0.0)\n#             elif 'weight' in name:\n#                 nn.init.orthogonal_(param, 0.1)\n\n    def compute_targets(self, recompute=False):\n        if recompute or self.targets is None:\n            self.targets = torch.zeros(self.batch_size, self.pred_steps, self.num_seq, self.batch_size).long()\n            for i in range(self.batch_size):\n                for j in range(self.pred_steps):\n                    self.targets[i, j, self.num_seq-self.pred_steps+j, i] = 1\n                    \n            self.targets = self.targets.cuda()\n            self.targets = self.targets.view(self.batch_size*self.pred_steps, self.num_seq*self.batch_size)\n            self.targets = self.targets.argmax(dim=1)\n            return self.targets\n        else:\n            return self.targets\n        \n    def forward(self, x):\n        # Extract feautres\n        # x: (batch, num_seq, channel, seq_len)\n        (batch, num_seq, channel, seq_len) = x.shape\n        x = x.view(batch*num_seq, channel, seq_len)\n        feature = self.encoder(x)\n        feature = feature.view(batch, num_seq, self.feature_dim) # (batch, num_seq, feature_dim)\n        \n        # Get context feature\n        h_0 = self.gru.init_hidden(self.batch_size)\n        # out: (batch, num_seq, hidden_size)\n        # h_n: (num_layers, batch, hidden_size)\n        out, h_n = self.gru(feature[:, :-self.pred_steps,:], h_0)\n        \n        # Get predictions\n        pred = []\n        h_next = h_n\n        c_next = out[:,-1,:].squeeze(1)\n        for i in range(self.pred_steps):\n            z_pred = self.predictor(c_next)\n            pred.append(z_pred)\n            c_next, h_next = self.gru(z_pred.unsqueeze(1), h_next)\n            c_next = c_next[:,-1,:].squeeze(1)\n        pred = torch.stack(pred, 1) # (batch, pred_step, feature_dim)\n        \n        # Compute scores\n        feature = feature.transpose(0, 2).contiguous() # (feature_dim, num_seq, batch)\n        pred = pred.contiguous()\n        \n        score = torch.einsum('ijk,kmn->ijmn', [pred, feature]) # (batch, pred_step, num_seq, batch)\n        score = score.view(batch*self.pred_steps, num_seq*batch)\n        \n        return score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Self-supervised Pre-training"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = SleepEDFDataset(path='../input/sleepedf-lite-0', seq_len=args.seq_len, \n                          stride=args.stride, return_label=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import random_split\nfrom torch.utils.data import DataLoader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = int(len(dataset)*args.train_ratio)\ntrain_dataset, test_dataset = random_split(dataset, [train_size, len(dataset)-train_size])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=args.batch_size, \n                          drop_last=True, shuffle=True, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = SleepContrast(input_channels=args.input_channels, hidden_channels=args.hidden_channels, \n                      feature_dim=args.feature_dim, pred_steps=args.pred_steps, \n                      batch_size=args.batch_size, num_seq=args.num_seq, kernel_sizes=[7, 11, 7])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), \n                       lr=args.learning_rate, betas=(0.9, 0.98), eps=1e-09, \n                       weight_decay=1e-4, amsgrad=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = model.compute_targets()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.train()\nfor epoch in range(args.epochs):\n    acc_list = []\n    loss_list = []\n    \n    for x, y in track(train_loader, description=f'EPOCH: [{epoch+1}/{args.epochs}]'):\n        x, y = x.cuda(), y.cuda()\n        \n        optimizer.zero_grad()\n        score = model(x)\n        loss = criterion(score, targets)\n        \n        loss.backward()\n        optimizer.step()\n        \n#         acc_list.append(acc.item())\n        loss_list.append(loss.item())\n        \n#         progress_bar.set_postfix({'loss': np.mean(loss_list)})\n    \n    print(f'Loss: {np.mean(loss_list)}')\n\n    if (epoch+1) % 10 == 0:\n        if not os.path.exists(args.save_path):\n            os.mkdir(args.save_path)\n        torch.save(model.state_dict(), os.path.join(args.save_path, f'model_epoch_{epoch}.pth'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fine-tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SleepClassifier(nn.Module):\n    def __init__(self, input_channels, hidden_channels, num_classes, feature_dim, pred_steps, num_seq, batch_size, kernel_sizes):\n        super(SleepClassifier, self).__init__()\n        \n        self.input_channels = input_channels\n        self.hidden_channels = hidden_channels\n        self.num_classes = num_classes\n        self.feature_dim = feature_dim\n        self.pred_steps = pred_steps\n        self.num_seq = num_seq\n        self.batch_size = batch_size\n        self.kernel_sizes = kernel_sizes\n        \n        \n        # Local Encoder\n        self.encoder = ResNet(input_channels, hidden_channels, feature_dim, kernel_sizes=kernel_sizes)\n        \n        # Aggregator\n        self.gru = GRU(input_size=feature_dim, hidden_size=feature_dim, num_layers=2)\n        \n        # Classifier\n        self.relu = nn.ReLU()\n        self.mlp = nn.Linear(feature_dim, num_classes)\n        \n    def freeze_parameters(self):\n        for p in self.encoder.parameters():\n            p.requires_grad = False\n        for p in self.gru.parameters():\n            p.requires_grad = False\n        \n    def forward(self, x):\n        # Extract feautres\n        # x: (batch, num_seq, channel, seq_len)\n        (batch, num_seq, channel, seq_len) = x.shape\n        x = x.view(batch*num_seq, channel, seq_len)\n        feature = self.encoder(x)\n        feature = feature.view(batch, num_seq, self.feature_dim) # (batch, num_seq, feature_dim)\n        \n        # Get context feature\n        h_0 = self.gru.init_hidden(self.batch_size)\n        # context: (batch, num_seq, hidden_size)\n        # h_n:     (num_layers, batch, hidden_size)\n        context, h_n = self.gru(feature[:, :-self.pred_steps,:], h_0)\n        \n        context = context[:, -1, :]\n        out = self.relu(context)\n        out = self.mlp(out)\n        \n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = SleepClassifier(input_channels=args.input_channels, hidden_channels=args.hidden_channels, \n                             num_classes=args.num_classes, feature_dim=args.feature_dim, \n                             pred_steps=args.pred_steps, batch_size=args.batch_size, \n                             num_seq=args.num_seq, kernel_sizes=[7, 11, 7])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = classifier.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copying encoder params\nfor finetune_param, pretraining_param in zip(classifier.encoder.parameters(), model.encoder.parameters()):\n    finetune_param.data = pretraining_param.data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copying gru params\nfor finetune_param, pretraining_param in zip(classifier.gru.parameters(), model.gru.parameters()):\n    finetune_param.data = pretraining_param.data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finetune_size = int(len(train_dataset)*args.finetune_ratio)\nfinetune_dataset, _ = random_split(train_dataset, [finetune_size, len(train_dataset)-finetune_size])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finetune_loader = DataLoader(finetune_dataset, batch_size=args.batch_size, \n                             drop_last=True, shuffle=True, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = optim.Adam(filter(lambda p: p.requires_grad, classifier.parameters()), \n                       lr=args.learning_rate, betas=(0.9, 0.98), eps=1e-09, \n                       weight_decay=1e-4, amsgrad=True)\ncriterion = nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.train()\n\nfor epoch in range(args.finetune_epochs):\n    for x, y in track(finetune_loader):\n        x, y = x.cuda(), y.cuda()\n            \n        optimizer.zero_grad()\n        y_hat = classifier(x)\n        print(y_hat.shape)\n        print(y.shape)\n        loss = criterion(y_hat, y[-1])\n            \n        loss.backward()\n        optimizer.step()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loader = DataLoader(test_dataset, batch_size=args.batch_size, \n                          drop_last=True, shuffle=True, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.eval()\n\npredictions = []\nlabels = []\nfor x, y in track(test_loader):\n    x, y = x.cuda(), y.cuda()\n    \n    with torch.no_grad():\n        y_hat = classifier(x)\n        \n    labels.append(y.cpu().numpy())\n    predictions.append(y_hat.cpu().numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = np.concatenate(labels, axis=0)\npredictions = np.concatenate(predictions, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = np.argmax(predictions, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(labels, predictions)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}