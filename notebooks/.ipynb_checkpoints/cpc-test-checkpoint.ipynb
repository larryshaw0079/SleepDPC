{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import namedtuple\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../input/sleepedf-lite-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config = namedtuple('Config', ['time_step', 'time_window', 'batch_size', \n",
    "                               'learning_rate', 'epochs', 'input_channel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Config(\n",
    "    time_step = 12,\n",
    "    time_window = 20480,\n",
    "    batch_size = 64,\n",
    "    learning_rate = 1e-3,\n",
    "    epochs = 30,\n",
    "    input_channel = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepEDFDataset(Dataset):\n",
    "    def __init__(self, path, num_context, num_future, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.num_context = num_context\n",
    "        self.num_future = num_future\n",
    "        \n",
    "        data = np.load(path)\n",
    "        self.data = np.concatenate((data['eeg_fpz_cz'].reshape(-1, 1, data['eeg_fpz_cz'].shape[-1]), data['eeg_pz_oz'].reshape(-1, 1, data['eeg_pz_oz'].shape[-1])), axis=1)\n",
    "        self.targets = data['annotation'] - 1\n",
    "        \n",
    "    def __len__(self):\n",
    "        return max(0, self.data.shape[0]-self.num_context-self.num_future)\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        if self.mode == 'train':\n",
    "            return torch.from_numpy(self.data[item+self.num_context+1+self.num_future].astype(np.float32))\n",
    "        else:\n",
    "            return (\n",
    "                    torch.from_numpy(self.data[item+self.num_context+1+self.num_future].astype(np.float32)),\n",
    "                    torch.from_numpy(self.targets[item+self.num_context+1+self.num_future].astype(np.long))\n",
    "                   )\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"\"\"\n",
    "               ****************************************\n",
    "               Model  : {self.__class__.__name__}\n",
    "               Length : {len(self)}\n",
    "               ****************************************\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.from_numpy(x_test.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.long))\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backbones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1d = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=1, padding=0, stride=1, bias=False),\n",
    "            nn.BatchNorm(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, padding=kernel_size//2, stride=1, bias=False),\n",
    "            nn.BatchNorm(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=1, padding=0, stride=1, bias=False)\n",
    "        )\n",
    "        \n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=1, padding=0, stride=1, bias=False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv1d(x) + self.shortcut(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Local Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalEncoder(nn.Module):\n",
    "    def __init__(self, input_channel=2, time_length=3000, output_channel=16, output_length=128):\n",
    "        super(LocalEncoder, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv1d(input_channel, output_channel, kernel_size=1, padding=0, stride=1, bias=False),\n",
    "            nn.BatchNorm1d(output_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=13, stride=13),\n",
    "            nn.Conv1d(output_channel, output_channel, kernel_size=1, padding=0, stride=1, bias=False),\n",
    "            nn.BatchNorm1d(output_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=13, stride=13),\n",
    "            nn.Conv1d(output_channel, output_channel, kernel_size=1, padding=0, stride=1, bias=False),\n",
    "        )\n",
    "        \n",
    "        self.avg_pool = nn.A\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.non_linear(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContextEncoder, self).__init__()\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=output_length, hidden_size=gru_hidden_size, \n",
    "                          num_layers=gru_layers, dropout=gru_dropout)\n",
    "        \n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatePredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StatePredictor, self).__init__()\n",
    "        \n",
    "        self.\n",
    "    \n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Sleep Contrast Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepContrast(nn.Module):\n",
    "    def __init__(self, feature_dim, num_context, num_future):\n",
    "        super(SleepContrast, self).__init__()\n",
    "        \n",
    "        self.feature_dim = feature_dim\n",
    "        self.num_context = num_context\n",
    "        self.num_future = num_future\n",
    "        \n",
    "        # Local Encoder\n",
    "        self.encoder = LocalEncoder(input_channel, time_length, output_channel, output_length)\n",
    "        \n",
    "        # Memory bank\n",
    "        memory_bank = torch.randn(total_size, output_length) \n",
    "        self.register_buffer('memory_bank', memory_bank)\n",
    "        \n",
    "        # Aggregator\n",
    "        self.aggregator = ContextEncoder()\n",
    "        en\n",
    "        # Predictor\n",
    "        self.predictor = StatePredictor()\n",
    "        \n",
    "    def _initialize_weights(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                nn.init.orthogonal_(param, 0.1)\n",
    "        \n",
    "    def compute_loss(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Get feautres\n",
    "        # x: (batch, num, channel, length)\n",
    "        (batch, num, channel, length) = x.shape\n",
    "        x = x.view(batch*num, channel, length)\n",
    "        feature = self.encoder(x)\n",
    "        feature = feature.view(batch, num, self.feature_dim)\n",
    "        \n",
    "        context = feature[:, :self.num_context+1, :].contiguous()\n",
    "#         anchor = feature[:, num_context, :].contiguous()\n",
    "        future = feature[:, -self.num_future, :].contiguous()\n",
    "        \n",
    "        # Predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CPC(args.time_step, args.batch_size, args.time_window, in_channel=args.input_channel)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(filter(lambda p : p.requires_grad, model.parameters()), \n",
    "                       lr=args.learning_rate, betas=(0.9, 0.98), eps=1e-09, \n",
    "                       weight_decay=1e-4, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(args.epochs):\n",
    "    acc_list = []\n",
    "    loss_list = []\n",
    "    with tqdm(train_dataloader, desc=f'EPOCH: [{epoch+1}/{args.epochs}]') as progress_bar:\n",
    "        for x, y, idx in progress_bar:\n",
    "            x, y, idx = x.cuda(), y.cuda(), idx.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            hidden = model.init_hidden(len(x), use_gpu=True)\n",
    "            acc, loss, hidden = model(x, hidden)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            acc_list.append(acc.item())\n",
    "            loss_list.append(loss.item())\n",
    "            \n",
    "            progress_bar.set_postfix({'loss': np.mean(loss_list), 'acc': np.mean(acc_list)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
